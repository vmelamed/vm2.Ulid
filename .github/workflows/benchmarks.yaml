name: Reusable - Benchmarks

on:
  workflow_call:
    inputs:
      os:
        description: "Runner OS-s"
        type: string
        required: true
        default: '["ubuntu-latest"]'

      dotnet-version:
        description: "Version of .NET SDK to use"
        type: string
        required: true
        default: "9.0.x"

      benchmark-project:
        description: "Path to the benchmark project"
        type: string
        required: false
        default: "./benchmarks/UlidType.Benchmarks/UlidType.Benchmarks.csproj"

      configuration:
        description: "The type of build to produce, e.g. Release vs Debug"
        type: string
        required: false
        default: "Release"

      defined-symbols:
        description: "Define constants to pass to the compiler"
        type: string
        required: false
        default: ""

      max-regression-pct:
        description: "Maximum acceptable performance regression percentage"
        type: number
        required: true
        default: 10 # percent

      force-new-baseline:
        description: "Ignore the existing baseline and force a new baseline"
        type: boolean
        required: false
        default: false

      verbose:
        description: "Whether to enable verbose logging for debugging scripts"
        type: boolean
        required: false
        default: false

permissions:
  contents: read

env:
  # these must be the same across all jobs and steps below.
  # We must know where to find the artifacts and where to download/upload to/from across all jobs and steps here.
  ARTIFACTS_DIR: ${{ github.workspace }}/BmArtifacts
  DOTNET_NOLOGO: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

jobs:
  benchmarks:
    name: Benchmarks (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: ${{ fromJSON(inputs.os) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ inputs.dotnet-version }}
          cache: true
          cache-dependency-path: |
            **/packages.lock.json
            **/*.csproj

      - name: Download baseline benchmark summaries artifact
        if: ${{ !inputs.force-new-baseline }}
        shell: bash
        run: >-
          ./scripts/bash/download-artifact.sh
          --repository ${{ github.repository }}
          --wf-name 'Reusable - Benchmarks'
          --artifact benchmark-summaries-${{ matrix.os }}
          --directory ${{ env.ARTIFACTS_DIR }}/baseline
          ${{ inputs.verbose && '--verbose' || '' }}

      - name: Run the benchmarks
        shell: bash
        env:
          FORCE_NEW_BASELINE: ${{ fromJSON(inputs.force-new-baseline) || false }}
          VERBOSE: ${{ fromJSON(inputs.verbose) || false }}
          DEFINED_SYMBOLS: ${{ inputs.defined-symbols || '' }}
        run: >-
          ./scripts/bash/run-benchmarks.sh ${{ inputs.benchmark-project }}
          --define "${{ inputs.defined-symbols }}"
          --configuration "${{ inputs.configuration }}"
          --artifacts "${{ env.ARTIFACTS_DIR }}"
          --max-regression-pct "${{ inputs.max-regression-pct }}"
          ${{ inputs.force-new-baseline && '--force-new-baseline' || '' }}
          ${{ inputs.verbose && '--verbose' || '' }}

      - name: Upload benchmark summaries artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-summaries-${{ matrix.os }}
          path: ${{ env.ARTIFACTS_DIR }}/summaries
          if-no-files-found: error
          overwrite: true
          retention-days: 5

      - name: Upload benchmark results artifact as a new baseline
        if: ${{ inputs.force-new-baseline || false }}
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-baseline-${{ matrix.os }}
          path: ${{ env.ARTIFACTS_DIR }}/baseline
          if-no-files-found: error
          overwrite: true
          retention-days: 5
