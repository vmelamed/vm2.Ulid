name: Reusable - Benchmarks

on:
  workflow_call:
    inputs:
      dotnet-version:
        description: "Version of .NET SDK to use"
        type: string
        default: "9.0.x"
        required: true

      benchmark-project:
        description: "Path to the benchmark project"
        type: string
        required: false

      configuration:
        description: "The type of build to produce, e.g. Release vs Debug"
        type: string
        required: false
        default: "Release"

      force-new-baseline:
        description: "Ignore the existing baseline and force a new baseline"
        type: boolean
        required: true
        default: false

      max-regression-pct:
        description: "Maximum acceptable performance regression percentage"
        type: number
        required: true
        default: 10 # percent

      os:
        description: "Runner OS-s"
        type: string
        required: true
        default: '["ubuntu-latest"]'

permissions:
  contents: read

env:
  # these must be the same across all jobs and steps
  CI: true
  ARTIFACTS_DIR: BmResults
  SUMMARIES_DIR: BmResults/summaries
  BASELINE_DIR: BmResults/baseline

jobs:
  benchmarks:
    name: Benchmarks (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: ${{ fromJSON(inputs.os) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ inputs.dotnet-version }}
          cache: true
          cache-dependency-path: |
            **/packages.lock.json
            **/*.csproj

      - name: Run benchmarks
        shell: bash
        env:
          FORCE_NEW_BASELINE: ${{ inputs.force-new-baseline }}
          CONFIGURATION: ${{ inputs.configuration }}
        run: ./scripts/bash/run-benchmarks.sh ${{ inputs.benchmark-project }}

      - name: Upload benchmark summaries artifact
        uses: actions/upload-artifact@v4
        with:
          name: summaries-${{ matrix.os }}
          path: ${{ env.SUMMARIES_DIR }}
          if-no-files-found: error
          overwrite: true
          retention-days: 90

      - name: Download baseline benchmark summaries artifact
        if: ${{ !inputs.force-new-baseline }}
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: benchmark-baseline-${{ matrix.os }}
          path: ${{ env.BASELINE_DIR }}

      - name: Compare benchmarks against baseline
        if: ${{ !inputs.force-new-baseline }}
        shell: bash
        env:
          MAX_REGRESSION_PCT: ${{ inputs.max-regression-pct }}
        run: |
          set -euo pipefail

          fs=$(ls ${SUMMARIES_DIR}/*-summary.json 2>/dev/null || true)
          if [ -z "${fs}" ]; then
            echo "No current benchmark result JSON files found."
            exit 2
          fi
          SUM_CUR=0
          for f in ${fs}; do
            VAL=$(jq '( .Totals.Mean // 0)' "${f}")
            SUM_CUR=$(( SUM_CUR + VAL ))
          done
          if (( SUM_CUR == 0 )); then
            echo "Current sum is invalid (${SUM_CUR})."
            exit 2
          fi

          fs=$(ls "${BASELINE_DIR}"/*-summary.json 2>/dev/null || true)
          if [[ -z "${fs}" ]]; then
            echo "Baseline reports were not found at ${BASELINE_DIR}."
            echo "FORCE_NEW_BASELINE=true" >> "$GITHUB_ENV"
            exit 0
          fi
          SUM_BASE=0
          for f in ${fs}; do
            VAL=$(jq '( .Totals.Mean // 0)' "${f}")
            SUM_BASE=$(( SUM_BASE + VAL ))
          done
          if (( SUM_BASE == 0 )); then
            echo "Baseline sum is invalid (${SUM_BASE})."
            exit 2
          fi

          pct=$(( (SUM_CUR - SUM_BASE) * 100 / SUM_BASE ))
          echo "Percent change vs baseline: ${pct}% (allowed: ${MAX_REGRESSION}%)"

          if (( pct > MAX_REGRESSION )); then
            echo "Performance regression exceeds threshold"
            exit 2
          elif (( pct > 0 )); then
            echo "Performance regression within acceptable threshold."
          elif (( pct < 0 )); then
            pct_abs=$(( -pct ))
            if (( pct_abs >= MAX_REGRESSION )); then
              echo "Significant improvement of ${pct_abs}% over baseline. Updating the baseline."
              echo "FORCE_NEW_BASELINE=true" >> "$GITHUB_ENV"
            else
              echo "Improvement of ${pct_abs}% over baseline."
            fi
          fi

      - name: Upload benchmark results artifact as a new baseline
        if: ${{ inputs.force-new-baseline || false }}
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-baseline-${{ matrix.os }}
          path: ${{ env.SUMMARIES_DIR }}
          if-no-files-found: error
          overwrite: true
          retention-days: 90
